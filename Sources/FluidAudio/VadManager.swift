import Foundation
import AVFoundation
import SoundAnalysis
import OSLog

/// Lean configuration for Voice Activity Detection
///
/// **Performance Note**: VAD optimized for smart ambient noise detection.
/// Filters obvious ambient noise (HVAC, fans, electrical hum) while preserving all speech.
/// Optimized to maintain DER â‰¤ 18% with improved efficiency.
public struct VadConfig: Sendable {
    public var enableVAD: Bool = true  // Optimized ambient noise detection enabled by default
    public var vadThreshold: Float = 0.3  // Optimized for ambient noise detection with best speed
    public var energyVADThreshold: Float = 0.003  // Smart ambient noise threshold
    public var debugMode: Bool = false

    public static let `default` = VadConfig()

    public init(
        enableVAD: Bool = true,
        vadThreshold: Float = 0.6,
        energyVADThreshold: Float = 0.01,
        debugMode: Bool = false
    ) {
        self.enableVAD = enableVAD
        self.vadThreshold = vadThreshold
        self.energyVADThreshold = energyVADThreshold
        self.debugMode = debugMode
    }
}

/// Lean Voice Activity Detection Manager
@available(macOS 13.0, iOS 16.0, *)
public final class VadManager: NSObject, SNResultsObserving, @unchecked Sendable {

    private let logger = Logger(subsystem: "com.fluidinfluence.vad", category: "VadManager")
    private let config: VadConfig
    private let soundAnalysisRequest: SNClassifySoundRequest?
    private var vadResults: [Bool] = []

    public init(config: VadConfig = .default) {
        self.config = config
        do {
            self.soundAnalysisRequest = try SNClassifySoundRequest(classifierIdentifier: .version1)
        } catch {
            self.soundAnalysisRequest = nil
        }
        super.init()
    }

    // MARK: - Essential Public API

    /// Simple speech detection - core functionality
    public func isSpeechDetected(in samples: [Float]) -> Bool {
        guard config.enableVAD else { return true }

        // Fast path: Use energy-based detection first (much faster than SoundAnalysis)
        let energy = calculateRMSEnergy(samples)
        if energy > config.energyVADThreshold * 2.0 {
            return true  // Clearly speech - skip expensive SoundAnalysis
        }
        
        if energy < config.energyVADThreshold * 0.3 {
            return false  // Clearly ambient noise - skip expensive SoundAnalysis  
        }
        
        // Only use SoundAnalysis for borderline cases
        if soundAnalysisRequest != nil {
            return isSpeechDetectedWithSoundAnalysis(in: samples)
        } else {
            return energy > config.energyVADThreshold
        }
    }

    /// Basic VAD filtering - core functionality
    public func detectVoiceActivity(in samples: [Float], windowSize: Int = 1600, threshold: Float? = nil) -> [Float] {
        guard config.enableVAD else { return samples }

        let vadThreshold = threshold ?? config.energyVADThreshold
        
        // Optimized: Use fast energy-based detection for most cases
        let energy = calculateRMSEnergy(samples)
        
        if energy > vadThreshold * 3.0 {
            return samples  // Clearly speech - no filtering needed
        }
        
        if energy < vadThreshold * 0.2 {
            return []  // Clearly ambient noise - filter completely
        }

        // Only use expensive processing for borderline cases
        if soundAnalysisRequest != nil {
            return detectVoiceActivityWithSoundAnalysis(in: samples)
        } else {
            return detectVoiceActivityWithEnergy(in: samples, windowSize: windowSize, threshold: vadThreshold)
        }
    }

    /// Check SoundAnalysis availability
    public var isSoundAnalysisAvailable: Bool {
        return soundAnalysisRequest != nil
    }

    /// RMS energy calculation - needed by DiarizerManager
    public func calculateRMSEnergy(_ samples: [Float]) -> Float {
        guard !samples.isEmpty else { return 0 }
        let squaredSum = samples.reduce(0) { $0 + $1 * $1 }
        return sqrt(squaredSum / Float(samples.count))
    }

    // MARK: - Private Implementation

    private func isSpeechDetectedWithSoundAnalysis(in samples: [Float]) -> Bool {
        guard let request = soundAnalysisRequest else { return false }

        vadResults.removeAll()
        guard let audioBuffer = createAudioBuffer(from: samples) else { return false }

        do {
            let analyzer = SNAudioStreamAnalyzer(format: audioBuffer.format)
            try analyzer.add(request, withObserver: self)
            analyzer.analyze(audioBuffer, atAudioFramePosition: 0)
            usleep(1000) // Brief wait for processing
        } catch {
            if config.debugMode {
                logger.error("SoundAnalysis failed: \(error.localizedDescription)")
            }
            return false
        }

        if vadResults.isEmpty {
            // Fallback to energy
            let energy = calculateRMSEnergy(samples)
            return energy > config.energyVADThreshold
        }

        let speechRatio = Double(vadResults.filter { $0 }.count) / Double(vadResults.count)
        return speechRatio >= 0.01  // Optimized ratio for ambient noise detection
    }

    private func detectVoiceActivityWithSoundAnalysis(in samples: [Float]) -> [Float] {
        guard let request = soundAnalysisRequest else { return samples }

        vadResults.removeAll()
        guard let audioBuffer = createAudioBuffer(from: samples) else { return samples }

        do {
            let analyzer = SNAudioStreamAnalyzer(format: audioBuffer.format)
            try analyzer.add(request, withObserver: self)
            analyzer.analyze(audioBuffer, atAudioFramePosition: 0)
        } catch {
            if config.debugMode {
                logger.error("SoundAnalysis failed: \(error.localizedDescription)")
            }
            return samples
        }

        return applyVADResults(to: samples)
    }

    private func detectVoiceActivityWithEnergy(in samples: [Float], windowSize: Int = 1600, threshold: Float = 0.01) -> [Float] {
        var segments: [Float] = []
        var current: [Float] = []
        var silenceCount = 0
        let maxSilenceFrames = 3  // Simple fixed value

        for i in stride(from: 0, to: samples.count, by: windowSize) {
            let end = min(i + windowSize, samples.count)
            let window = Array(samples[i..<end])
            let energy = calculateRMSEnergy(window)

            if energy > threshold {
                silenceCount = 0
                current.append(contentsOf: window)
            } else {
                silenceCount += 1
                if !current.isEmpty && silenceCount <= maxSilenceFrames {
                    current.append(contentsOf: window)
                } else if !current.isEmpty {
                    if current.count >= windowSize * 2 {  // Simple minimum length
                        segments.append(contentsOf: current)
                    }
                    current.removeAll()
                    silenceCount = 0
                }
            }
        }

        if !current.isEmpty && current.count >= windowSize * 2 {
            segments.append(contentsOf: current)
        }

        return segments.isEmpty ? samples : segments
    }

    private func createAudioBuffer(from samples: [Float]) -> AVAudioPCMBuffer? {
        let format = AVAudioFormat(commonFormat: .pcmFormatFloat32, sampleRate: 16000, channels: 1, interleaved: false)
        guard let audioFormat = format else { return nil }

        let buffer = AVAudioPCMBuffer(pcmFormat: audioFormat, frameCapacity: AVAudioFrameCount(samples.count))
        guard let audioBuffer = buffer else { return nil }

        audioBuffer.frameLength = audioBuffer.frameCapacity

        if let channelData = audioBuffer.floatChannelData?[0] {
            for i in 0..<samples.count {
                channelData[i] = samples[i]
            }
        }

        return audioBuffer
    }

    private func applyVADResults(to samples: [Float]) -> [Float] {
        guard !vadResults.isEmpty else { return samples }

        var filteredSamples: [Float] = []
        let samplesPerVADResult = samples.count / vadResults.count

        for (index, isSpeech) in vadResults.enumerated() {
            if isSpeech {
                let startIndex = index * samplesPerVADResult
                let endIndex = min((index + 1) * samplesPerVADResult, samples.count)
                filteredSamples.append(contentsOf: samples[startIndex..<endIndex])
            }
        }

        return filteredSamples.isEmpty ? samples : filteredSamples
    }

    // MARK: - SNResultsObserving

    public func request(_ request: SNRequest, didProduce result: SNResult) {
        guard let classificationResult = result as? SNClassificationResult else { return }

        let speechConfidence = classificationResult.classifications.first { classification in
            classification.identifier == "Speech" ||
            classification.identifier.contains("speech") ||
            classification.identifier.contains("voice")
        }?.confidence ?? 0.0

        let isSpeech = speechConfidence > Double(config.vadThreshold)
        vadResults.append(isSpeech)

        if config.debugMode {
            logger.debug("Speech confidence: \(speechConfidence), isSpeech: \(isSpeech)")
        }
    }

    public func request(_ request: SNRequest, didFailWithError error: Error) {
        if config.debugMode {
            logger.error("SoundAnalysis failed: \(error.localizedDescription)")
        }
    }

    public func requestDidComplete(_ request: SNRequest) {
        // Optional completion handling
    }

    // MARK: - Cleanup

    public func cleanup() {
        vadResults.removeAll()
    }
}
